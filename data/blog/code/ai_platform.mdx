---
title: AI Platform
date: '2024-11-23'
tags: ['deep learning', 'AI Platform']
draft: false
summary: 'Building a scalable AI platform for diverse AI workloads using Ray Cluster'
---
Deep learning has been demonstrated to be effective in solving a wide range of problems, from image and speech recognition to natural language processing and even playing complex games. However, deploying them in production can be challenging due to the complexity and resource requirements of deep learning models.

Usually, deploying a deep learning model involves several steps, including data preprocessing, model training, model evaluation, and model serving. Each step requires a different type of hardware and software, and the process can be time-consuming and error-prone.

In this post, we provide a step-by-step guide to building a scalable and unified AI platform using Ray. This platform enables you to scale different workloads within a single line of code, making it easier to deploy and manage deep learning models in production.

Full code is available [here](https://github.com/Jason-cs18/mlsys_code/tree/main/ai_platform).

<details>
<summary><b>Table of Contents</b> (click to open)</summary>

- [Why Ray?](#why-ray)
- [Install Ray](#install-ray)
    - [Pre-requisite](#pre-requisite)
    - [Install Ray Cluster](#install-ray-cluster)
    - [Setup Ray Cluster](#setup-ray-cluster)
    - [Submit AI jobs via ray job submission SDK](#submit-ai-jobs-via-ray-job-submission-sdk)
- [Hands-on examples](#hands-on-examples)
- [Monitoring and logging](#monitoring-and-logging)
- [References](#references)

</details>

## Why Ray?
Ray is an open-source distributed computing framework designed to streamline the development of distributed applications for all AI workloads. It achieves this by offering a three-layer architecture: Ray AI libraries, Ray Core, and Ray Cluster. With Ray, users can concentrate on building their AI applications without having to concern themselves with the complexities of the underlying cloud infrastructure.

Today, Ray has been widely adopted by numerous companies, including industry leaders such as Uber, OpenAI, and Microsoft.

![](https://docs.ray.io/en/latest/_images/map-of-ray.svg)

Ray Cluster integrates seamlessly with Kubernetes, enabling the deployment of AI platforms both on-premises and in the cloud. Additionally, it offers a scalable and fault-tolerant storage system, simplifying the management of large-scale data and models.

![](https://docs.ray.io/en/latest/_images/ray-cluster.svg)

![](https://docs.ray.io/en/latest/_images/ray_on_kubernetes.png)

After running Ray Cluster, users can easily submit their AI jobs via Ray job submission SDK.
![](https://docs.ray.io/en/latest/_images/ray-job-diagram.svg)

## Install Ray

### Pre-requisite

### Install Ray Cluster

### Setup Ray Cluster

### Submit AI jobs via ray job submission SDK
- How to handle different dependencies?

## Hands-on examples

- [Data analysis on MNIST dataset]()
- [Multimodal data analysis with LanceDB]()
    - [LanceDB: an open-source vector database for AI that's designed to store, manage, query and retrieve embeddings on large-scale multi-modal data. ](https://lancedb.github.io/lancedb/)
    - [Transforming Multimodal Data Management with LanceDB-Ray](https://www.youtube.com/watch?v=xmTFEzAh8ho)
- [Train a ResNet on MNIST dataset]()
- [Inference on MNIST dataset]()
- [Serve a ResNet with Ray Serve]()
- [Serve a LLM with vLLM]()

## Monitoring and logging

## References
1. AnyScale. ["Welcome to Ray! (2.39.0)"](https://docs.ray.io/en/latest/index.html) (2024)
2. 字节跳动云原生计算. ["基于 Ray 的大规模离线推理"](https://mp.weixin.qq.com/s/pS5RJCA5O_s6pPcib0JsuQ) (2023)